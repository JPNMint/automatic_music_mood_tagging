{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/ykinoshita/humrec_mood_tagger/mood_tagger_master_thesis_V2/Testing/testing_loading_pth.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdavinci/home/ykinoshita/humrec_mood_tagger/mood_tagger_master_thesis_V2/Testing/testing_loading_pth.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39momegaconf\u001b[39;00m \u001b[39mimport\u001b[39;00m OmegaConf\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdavinci/home/ykinoshita/humrec_mood_tagger/mood_tagger_master_thesis_V2/Testing/testing_loading_pth.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdavinci/home/ykinoshita/humrec_mood_tagger/mood_tagger_master_thesis_V2/Testing/testing_loading_pth.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m test_model, get_architecture\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdavinci/home/ykinoshita/humrec_mood_tagger/mood_tagger_master_thesis_V2/Testing/testing_loading_pth.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdavinci/home/ykinoshita/humrec_mood_tagger/mood_tagger_master_thesis_V2/Testing/testing_loading_pth.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m run_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/home/ykinoshita/humrec_mood_tagger/mood_tagger_master_thesis_V2/architectures/SotA\u001b[39m\u001b[39m'\u001b[39m \u001b[39m#musicnn mse loss\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "from __init__ import test_model, get_architecture\n",
    "\n",
    "import torch\n",
    "\n",
    "run_path = '/home/ykinoshita/humrec_mood_tagger/mood_tagger_master_thesis_V2/architectures/SotA' #musicnn mse loss\n",
    "hydra_run_path = os.path.join(run_path, '.hydra')\n",
    "config_path = os.path.join(hydra_run_path, 'config.yaml')\n",
    "# overrides_path = os.path.join(hydra_run_path, 'overrides.yaml')\n",
    "cfg = OmegaConf.load(config_path)\n",
    "\n",
    "\n",
    "\n",
    "#https://discuss.pytorch.org/t/how-to-load-part-of-pre-trained-model/1113/16\n",
    "\n",
    "# Load the pre-trained musicnn model\n",
    "#musicnn_model = torch.load('/home/ykinoshita/humrec_mood_tagger/mood_tagger_master_thesis_V2/architectures/SotA/musicnn_sota.pth')\n",
    "\n",
    "# Assuming the output feature is the last layer of musicnn\n",
    "# Extract the feature extractor part of the model (without the final prediction layers)\n",
    "\n",
    "\n",
    "architecture, architecture_file = get_architecture(cfg.model.architecture, None)\n",
    "\n",
    "model = architecture(audio_input=cfg.model.audio_inputs, num_classes=9, debug=False, **cfg.features)\n",
    "\n",
    "\n",
    "pretrained_dict = torch.load('/home/ykinoshita/humrec_mood_tagger/mood_tagger_master_thesis_V2/architectures/SotA/musicnn_sota.pth')\n",
    "del pretrained_dict['dense2.weight']\n",
    "del pretrained_dict['dense2.bias']\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "# 1. filter out unnecessary keys\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(pretrained_dict) \n",
    "# 3. load the new state dict\n",
    "model.load_state_dict(pretrained_dict)\n",
    "\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    musicnn_features = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "pretrained_dict = torch.load('/home/ykinoshita/humrec_mood_tagger/mood_tagger_master_thesis_V2/architectures/SotA/musicnn_sota.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spec.spectrogram.window',\n",
       " 'spec.mel_scale.fb',\n",
       " 'spec_bn.weight',\n",
       " 'spec_bn.bias',\n",
       " 'spec_bn.running_mean',\n",
       " 'spec_bn.running_var',\n",
       " 'spec_bn.num_batches_tracked',\n",
       " 'layers.0.conv.weight',\n",
       " 'layers.0.conv.bias',\n",
       " 'layers.0.bn.weight',\n",
       " 'layers.0.bn.bias',\n",
       " 'layers.0.bn.running_mean',\n",
       " 'layers.0.bn.running_var',\n",
       " 'layers.0.bn.num_batches_tracked',\n",
       " 'layers.1.conv.weight',\n",
       " 'layers.1.conv.bias',\n",
       " 'layers.1.bn.weight',\n",
       " 'layers.1.bn.bias',\n",
       " 'layers.1.bn.running_mean',\n",
       " 'layers.1.bn.running_var',\n",
       " 'layers.1.bn.num_batches_tracked',\n",
       " 'layers.2.conv.weight',\n",
       " 'layers.2.conv.bias',\n",
       " 'layers.2.bn.weight',\n",
       " 'layers.2.bn.bias',\n",
       " 'layers.2.bn.running_mean',\n",
       " 'layers.2.bn.running_var',\n",
       " 'layers.2.bn.num_batches_tracked',\n",
       " 'layers.3.conv.weight',\n",
       " 'layers.3.conv.bias',\n",
       " 'layers.3.bn.weight',\n",
       " 'layers.3.bn.bias',\n",
       " 'layers.3.bn.running_mean',\n",
       " 'layers.3.bn.running_var',\n",
       " 'layers.3.bn.num_batches_tracked',\n",
       " 'layers.4.conv.weight',\n",
       " 'layers.4.conv.bias',\n",
       " 'layers.4.bn.weight',\n",
       " 'layers.4.bn.bias',\n",
       " 'layers.4.bn.running_mean',\n",
       " 'layers.4.bn.running_var',\n",
       " 'layers.4.bn.num_batches_tracked',\n",
       " 'layer1.conv.weight',\n",
       " 'layer1.conv.bias',\n",
       " 'layer1.bn.weight',\n",
       " 'layer1.bn.bias',\n",
       " 'layer1.bn.running_mean',\n",
       " 'layer1.bn.running_var',\n",
       " 'layer1.bn.num_batches_tracked',\n",
       " 'layer2.conv.weight',\n",
       " 'layer2.conv.bias',\n",
       " 'layer2.bn.weight',\n",
       " 'layer2.bn.bias',\n",
       " 'layer2.bn.running_mean',\n",
       " 'layer2.bn.running_var',\n",
       " 'layer2.bn.num_batches_tracked',\n",
       " 'layer3.conv.weight',\n",
       " 'layer3.conv.bias',\n",
       " 'layer3.bn.weight',\n",
       " 'layer3.bn.bias',\n",
       " 'layer3.bn.running_mean',\n",
       " 'layer3.bn.running_var',\n",
       " 'layer3.bn.num_batches_tracked',\n",
       " 'dense1.weight',\n",
       " 'dense1.bias',\n",
       " 'bn.weight',\n",
       " 'bn.bias',\n",
       " 'bn.running_mean',\n",
       " 'bn.running_var',\n",
       " 'bn.num_batches_tracked',\n",
       " 'dense2.weight',\n",
       " 'dense2.bias']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(pretrained_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model: transfer_learning\n",
      "Freeze pretrained model!\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "from __init__ import test_model, get_architecture\n",
    "\n",
    "import torch\n",
    "\n",
    "run_path = '/home/ykinoshita/humrec_mood_tagger/mood_tagger_master_thesis_V2/architectures/SotA' #musicnn mse loss\n",
    "hydra_run_path = os.path.join(run_path, '.hydra')\n",
    "config_path = os.path.join(hydra_run_path, 'config.yaml')\n",
    "# overrides_path = os.path.join(hydra_run_path, 'overrides.yaml')\n",
    "cfg = OmegaConf.load(config_path)\n",
    "\n",
    "architecture, architecture_file = get_architecture(cfg.model.architecture, None)\n",
    "\n",
    "\n",
    "model = architecture(audio_input=cfg.model.audio_inputs, num_classes=9, debug=False, **cfg.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing spectrogram (w/ librosa) and tags (w/ tensorflow).. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ykinoshita/humrec_mood_tagger/musicnn_env3.9/lib/python3.9/site-packages/librosa-0.10.1-py3.9.egg/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "from musicnn.extractor import extractor\n",
    "taggram, tags, features = extractor('/home/ykinoshita/humrec_mood_tagger/mood_tagger_master_thesis_V2/data/audio/P_Shakira_HipsDon.mp3', model='MTT_musicnn', extract_features=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mood_tagger_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
